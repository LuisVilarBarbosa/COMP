**PROJECT TITLE: Auto
**GROUP: G15

NAME1: Diogo Cruz, NR1: up201105483, GRADE1: <0 to 20 value>, CONTRIBUTION1: <0 to 100 %>

NAME2: Luís Barbosa, NR2: up201405729, GRADE2: <0 to 20 value>, CONTRIBUTION2: <0 to 100 %>

NAME3: Paulo Santos, NR3: up201403745, GRADE3: <0 to 20 value>, CONTRIBUTION3: <0 to 100 %>

NAME4: Sérgio Ferreira, NR4: up201403074, GRADE4: <0 to 20 value>, CONTRIBUTION4: <0 to 100 %>
 
** SUMMARY: 

An autotuner for C programs. The user adds pragmas to the source code and the auto-tuner automatically determines the best values for some constants.
The available pragmas are:
#pragma tuner explore STEP(x,y) reference(STEP=z) (x > y, y > z > x, step is 1)
#pragma tuner explore STEP(x,y,z) reference(STEP=k) (x > y, y > k > x, z is the step)
#pragma tuner random RANDOM(x,y,N) reference(RANDOM=z) (x > y, y > z > x, N is the number of random numbers to generate)

 
** EXECUTE: 

Initially, the files that are generated by JJTree and JavaCC are already in the JJTree folder. 
However, if you prefer to generate new files you can run the script 'JJTreeRunner', considering your operating system.
After that, go to the scripts folder and run the script 'CompileAuto', followed by 'ExecuteAuto', considering your operating system.
 
**DEALING WITH SYNTACTIC ERRORS:

The syntactic analyser is implemented in JJTree. If any error occur, our tool goes to the next test file.
 
**SEMANTIC ANALYSIS: (Refer the possible semantic rules implemented by your tool.)

In our tool, we consider important to implement five semantic rules. They are:
- Verify if the pragma data types are equal: we look for all the values used in the pragma, and make sure that they are all integers or doubles.
- Verify if the interval indicated in the pragma is in the correct order.
- Verify if is possible to pass through the value referenced in the pragma, considering the interval that is declared, and the step.
- 
 
**INTERMEDIATE REPRESENTATIONS (IRs): (for example, when applicable, briefly describe the HLIR (high-level IR) and the LLIR (low-level IR) used, if your tool includes an LLIR with structure different from the HLIR)
 
**CODE GENERATION: (when applicable, describe how the code generation of your tool works and identify the possible problems your tool has regarding code generation.)
 
**OVERVIEW: (refer the approach used in your tool, the main algorithms, the third-party tools and/or packages, etc.)
 
**TESTSUITE AND TEST INFRASTRUCTURE: (Describe the content of your testsuite regarding the number of examples, the approach to automate the test, etc.)
 
**TASK DISTRIBUTION: (Identify the set of tasks done by each member of the project.)
 
**PROS: (Identify the most positive aspects of your tool)
 
**CONS: (Identify the most negative aspects of your tool)